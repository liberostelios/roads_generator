{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import basic libraries\n",
    "\n",
    "Let's import some basic stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "- Add the nodes in the CityJSON file, keeping the relationships between nodes and edges (linestrings). The nodes have semantics and atttributes.\n",
    "- Find a small area and compute widths.\n",
    "- Create LoD0.1 with single lines and attributes for two-way and same for LoD0.2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ideas for modelling\n",
    "\n",
    "1. Every city object contains `MultiPoints` (nodes of LoD0.1), `MultiLineStrings` (edges of LoD0.1) and `MultiSurfaces `(for LoD1+).\n",
    "2. Every city object contains `MultiLineStrings` (geometry of edges of LoD0.1) and `MultiSurfaces` (for LoD1+). The network topology (nodes and edges) is defined in its own `\"+network\"` portion of the city model.\n",
    "3. Every city object has its own `MultiSurfaces` (for LoD1+). Then the actual network (nodes, edges and their geometry) is stored in `\"+network\"`.\n",
    "4. Every node is its own city object. Every edge is its own city object. Every surface is its own city object. Then `CityObjectGroups` are used to relate them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix for `fiona`\n",
    "\n",
    "*`fiona` has an issue with GDAL 3.0. Better set your `GDAL_DATA` path to fiona's installation (contains GDAL 2.4.4) prior to running this script.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas\n",
    "import pandas as pd\n",
    "import osmnx as ox\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the OSM data\n",
    "\n",
    "This will load the osm file to a network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We don't want edges to be loaded twice\n",
    "ox.config(all_oneway=True)\n",
    "\n",
    "network_graph = ox.graph_from_file('../data/Breda/Breda extract.osm', simplify=False)\n",
    "# We simplify the graph afterwards, so that osmids are not \"smashed\" together\n",
    "network_graph = ox.simplify_graph(network_graph, strict=False)\n",
    "edges = ox.graph_to_gdfs(network_graph, nodes=False, node_geometry=False)\n",
    "\n",
    "edges = edges.to_crs(\"EPSG:28992\")\n",
    "\n",
    "len(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, e = ox.graph_to_gdfs(network_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Play with the graph data\n",
    "Those a little experimentation for me (nothing useful here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e.iloc[0]\n",
    "\n",
    "n.loc[[e.iloc[0]['u'], e.iloc[0]['v']]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ec = ['r' if data['oneway'] else 'b' for u, v, key, data in network_graph.edges(keys=True, data=True)]\n",
    "ox.plot_graph(network_graph, file_format='svg', save=True, filename='ways', fig_height=15, edge_color=ec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keys import google_elevation_api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter drive and service roads only\n",
    "\n",
    "Filter roads to only motorways:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highway_types = [\n",
    "    \"primary\",\n",
    "    \"secondary\",\n",
    "    \"motorway\",\n",
    "    \"trunk\",\n",
    "    \"tertiary\",\n",
    "    \"unclassified\",\n",
    "    \"residential\",\n",
    "\n",
    "    \"motorway_link\",\n",
    "    \"trunk_link\",\n",
    "    \"primary_link\",\n",
    "    \"secondary_link\",\n",
    "    \"tertiary_link\",\n",
    "\n",
    "    \"living_street\",\n",
    "    \"service\",\n",
    "    \"pedestrian\",\n",
    "    \"track\",\n",
    "    \"bus_guideway\",\n",
    "    \"escape\",\n",
    "    \"raceway\",\n",
    "    \"road\"\n",
    "]\n",
    "\n",
    "road_edges = edges[(edges['highway'].isin(highway_types)) & (edges['area'] != 'yes')]\n",
    "\n",
    "road_edges.to_file('output/road_edges.geojson', driver='GeoJSON')\n",
    "len(road_edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now `road_edges` has duplicate edges (because twoway roads are modeled as two opposite order linestrings). Let's discard those duplicates (we'll rely on semantics here):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lexicographic_uv(f):\n",
    "    if f['u'] > f['v']:\n",
    "        return str(f['v']) + \"-\" + str(f['u'])\n",
    "    else:\n",
    "        return str(f['u']) + \"-\" + str(f['v'])\n",
    "\n",
    "road_edges = road_edges.copy()\n",
    "    \n",
    "road_edges['uv'] = road_edges.apply(lexicographic_uv, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the BGT data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bgt_roads = geopandas.read_file('../data/Breda/bgt_roads.geojson')\n",
    "\n",
    "len(bgt_roads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute primary-secondary road polygons\n",
    "\n",
    "We need to assign secondary road polygons (parking spaces, sidewalks) to the primary roads\n",
    "\n",
    "### Filter primary roads\n",
    "\n",
    "Primary types are those that vehicles are supposed to move:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bgt_road_types = [\n",
    "    'rijbaan lokale weg',\n",
    "    'rijbaan regionale weg',\n",
    "    # 'overweg' # Maybe?\n",
    "]\n",
    "\n",
    "bgt_roads =  bgt_roads[bgt_roads['eindRegistratie'].isnull()]\n",
    "\n",
    "bgt_roads['parent_gml_id'] = bgt_roads['gml_id']\n",
    "\n",
    "bgt_main_roads = bgt_roads[bgt_roads['function'].isin(bgt_road_types)]\n",
    "\n",
    "len(bgt_main_roads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify parent for every secondary road\n",
    "\n",
    "Find the secondary roads that touch the main ones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bgt_secondary_roads = bgt_roads[~bgt_roads['function'].isin(bgt_road_types)]\n",
    "\n",
    "len(bgt_secondary_roads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Old way\n",
    "**TODO:** We need to improve the way that main road is assigned (get the one with the highest shared boundary, not just a random one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined = geopandas.sjoin(bgt_secondary_roads, bgt_main_roads, how='left', op='intersects')\n",
    "\n",
    "joined = joined[['gml_id_left', 'function_left', 'gml_id_right', 'geometry']]\n",
    "joined.columns = ['gml_id', 'function', 'parent_gml_id', 'geometry']\n",
    "\n",
    "bgt_roads_parented = geopandas.GeoDataFrame(joined.groupby('gml_id').aggregate('first').reset_index(), crs='EPSG:28992')\n",
    "\n",
    "len(bgt_roads_parented)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New way\n",
    "Let's overlay the secondary roads with the main roads. The result should be (mostly) linestrings accross their common boundaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bgt_common_boundaries = geopandas.overlay(bgt_secondary_roads, bgt_main_roads, how='intersection', keep_geom_type=False)\n",
    "\n",
    "len(bgt_common_boundaries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to compute the longest common boundary per `gml_id` to pick the respective parent `gml_id`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bgt_common_boundaries['length'] = bgt_common_boundaries['geometry'].length\n",
    "\n",
    "max_rows = bgt_common_boundaries[['gml_id_1', 'function_1', 'gml_id_2', 'geometry', 'length']].groupby('gml_id_1')['length'].idxmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's join this with the original secondary rows table to bring back their original geometries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_roads = bgt_common_boundaries.loc[max_rows]\n",
    "temp_roads = temp_roads[['gml_id_1', 'function_1', 'gml_id_2', 'geometry']]\n",
    "temp_roads = temp_roads.rename(columns={'gml_id_1': 'gml_id', 'function_1': 'function', 'gml_id_2': 'parent_gml_id'})\n",
    "temp_roads = temp_roads.set_index('gml_id')\n",
    "\n",
    "bgt_roads_parented = temp_roads.merge(bgt_secondary_roads.set_index('gml_id'), on='gml_id', suffixes=('', '_right'))\n",
    "bgt_roads_parented = bgt_roads_parented[['function', 'parent_gml_id', 'geometry_right']].rename(columns={'geometry_right': 'geometry'})\n",
    "bgt_roads_parented = bgt_roads_parented.reset_index()\n",
    "\n",
    "bgt_roads_parented = geopandas.GeoDataFrame(bgt_roads_parented, crs='EPSG:28992')\n",
    "\n",
    "len(bgt_roads_parented)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge primary and secondary roads\n",
    "\n",
    "Concatenate everything:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bgt_all_roads = pd.concat([bgt_roads_parented, bgt_main_roads[['gml_id', 'function', 'parent_gml_id', 'geometry']]])\n",
    "\n",
    "bgt_all_roads.to_file('output/bgt_all_roads.geojson', driver='GeoJSON')\n",
    "\n",
    "len(bgt_all_roads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intersect roads network with polygon\n",
    "First, we intersect the road lines with the BGT polygons (to create nodes at the polygon boundaries):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roads = geopandas.overlay(road_edges, bgt_all_roads, how='intersection')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export the intersected roads to `GeoJSON`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "roads.to_file('output/roads.json', driver='GeoJSON')\n",
    "\n",
    "roads.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export to CityJSON\n",
    "\n",
    "Let's export everything to CityJSON.\n",
    "\n",
    "First, we'll define how the established intersected lines will be translated to `Road` objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_ring(line, vertices):\n",
    "    \"\"\"Returns the boundaries array of a single linear rings.\n",
    "    \n",
    "    Arguments:\n",
    "    line -- The LineString to be processed (represents the ring)\n",
    "    vertices -- the global vertices list of the CityJSON\n",
    "    \"\"\"\n",
    "    points = [[x, y, 0] for x, y in list(line.coords)]\n",
    "    indices = [i + len(vertices) for i in range(len(points))]\n",
    "    for p in points:\n",
    "        vertices.append(p)\n",
    "\n",
    "    return indices\n",
    "\n",
    "def process_linestring(geom, vertices):\n",
    "    \"\"\"Returns the boundaries array of a linear element.\n",
    "    \n",
    "    This can process LineString or MultiLineString geometries.\n",
    "    \n",
    "    Arguments:\n",
    "    geom -- the (linear) geometry to be processed\n",
    "    vertices -- the global vertices list of the CityJSON\n",
    "    \"\"\"\n",
    "    if geom.type == \"LineString\":\n",
    "        indices = [process_ring(geom, vertices)]\n",
    "    else:\n",
    "        indices = []\n",
    "        \n",
    "        for l in geom.geoms:\n",
    "            indices.append(process_ring(l, vertices))\n",
    "        \n",
    "    return indices\n",
    "\n",
    "def create_geometry(geom, lod, vertices):\n",
    "    \"\"\"Returns a CityJSON geometry from a single shapely geometry.\n",
    "    \n",
    "    This will also append the 'vertices' list with new vertices.\n",
    "    \n",
    "    Arguments:\n",
    "    geom -- the shapely geometry to be processed\n",
    "    lod -- the lod of the resulting CityJSON geometry\n",
    "    vertices -- the global vertices list of the CityJSON\n",
    "    \"\"\"\n",
    "    indices = []\n",
    "    \n",
    "    if geom.type == \"LineString\" or geom.type == \"MultiLineString\":\n",
    "        geom_type = \"MultiLineString\"\n",
    "        \n",
    "        indices = process_linestring(geom, vertices)\n",
    "    elif geom.type == \"Polygon\":\n",
    "        geom_type = \"MultiSurface\"\n",
    "        \n",
    "        indices = [process_linestring(geom.boundary, vertices)]\n",
    "    else:\n",
    "        raise TypeError(geom.type)\n",
    "    \n",
    "    return {\n",
    "        \"type\": geom_type,\n",
    "        \"lod\": lod,\n",
    "        \"boundaries\": indices\n",
    "    }\n",
    "\n",
    "def create_geom_with_semantics(map_func, features, lod, vertices, geom_column='geometry'):\n",
    "    \"\"\"Returns a CityJSON geometry with semantic elements from multiple features.\n",
    "    \n",
    "    Semantic elements are semantic lines (for LineString) or surfaces (for\n",
    "    MultiSurface).\n",
    "    \n",
    "    Arguments:\n",
    "    map_func -- function that maps an input feature to an output semantic element\n",
    "    features -- list of features to be processed\n",
    "    lod -- the lod of the resulting CityJSON geometry\n",
    "    vertices -- the global vertices list of the CityJSON\n",
    "    \"\"\"\n",
    "    boundaries = []\n",
    "    semantics = {\n",
    "        \"surfaces\": [],\n",
    "        \"values\": []\n",
    "    }\n",
    "    \n",
    "    # Get the resulting geometry type from the first feature\n",
    "    geom = features[0][geom_column]\n",
    "    if geom.type == \"LineString\" or geom.type == \"MultiLineString\":\n",
    "        geom_type = \"MultiLineString\"\n",
    "    elif geom.type == \"Polygon\":\n",
    "        geom_type = \"MultiSurface\"\n",
    "    else:\n",
    "        raise TypeError(geom.type)\n",
    "    \n",
    "    # Process all features\n",
    "    i = 0\n",
    "    for f in features:\n",
    "        surface = map_func(f)\n",
    "        \n",
    "        if geom_type == \"MultiLineString\":\n",
    "            indices = process_linestring(f[geom_column], vertices)\n",
    "            for l in indices:\n",
    "                boundaries.append(l)\n",
    "                semantics[\"surfaces\"].append(surface)\n",
    "                semantics[\"values\"].append(i)\n",
    "                i = i + 1\n",
    "        else:\n",
    "            indices = process_linestring(f[geom_column].boundary, vertices)\n",
    "        \n",
    "            boundaries.append(indices)\n",
    "            semantics[\"surfaces\"].append(surface)\n",
    "            semantics[\"values\"].append(i)\n",
    "            i = i + 1\n",
    "    \n",
    "    return {\n",
    "        \"type\": geom_type,\n",
    "        \"lod\": lod,\n",
    "        \"boundaries\": boundaries,\n",
    "        \"semantics\": semantics\n",
    "    }\n",
    "\n",
    "def osm_semantics_map(feature):\n",
    "    obj = {\n",
    "        \"type\": feature['highway'],\n",
    "        \"osm_id\": feature['osmid'],\n",
    "        \"oneway\": feature['oneway'] if isinstance(feature['oneway'], str) else \"no\"\n",
    "    }\n",
    "    \n",
    "    if isinstance(feature['name'], str):\n",
    "        obj[\"name\"] = feature['name']\n",
    "    \n",
    "    if isinstance(feature['maxspeed'], str):\n",
    "        obj[\"maxspeed\"] = feature['maxspeed']\n",
    "    \n",
    "    return obj\n",
    "\n",
    "def bgt_semantics_map(feature):\n",
    "    return {\n",
    "        \"type\": feature['function'],\n",
    "        \"gml_id\": feature['gml_id']\n",
    "    }\n",
    "\n",
    "def create_cityobject(feature, vertices):\n",
    "    \"\"\"Create a CityJSON city object from a single OSM linear features.\"\"\"\n",
    "    return {\n",
    "        \"type\": \"Road\",\n",
    "        \"attributes\": {\n",
    "            \"osm_id\": feature['osmid'],\n",
    "            \"highway\": feature['highway'],\n",
    "        },\n",
    "        \"geometry\": [\n",
    "            create_geometry(feature['geometry'], \"0.1\", vertices)\n",
    "        ]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's run this against all intersected road segments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vertices = []\n",
    "objects = {}\n",
    "\n",
    "road_groups = roads.groupby('parent_gml_id')\n",
    "\n",
    "for gml_id, group in road_groups:\n",
    "    features = [f for i, f in group.iterrows()]\n",
    "    objects[gml_id] = {\n",
    "        \"type\": \"Road\",\n",
    "        \"geometry\": [\n",
    "            create_geom_with_semantics(osm_semantics_map,\n",
    "                                       features,\n",
    "                                       '0.1',\n",
    "                                       vertices)\n",
    "        ]\n",
    "    }\n",
    "\n",
    "bgt_roads_groups = bgt_all_roads.groupby('parent_gml_id')\n",
    "\n",
    "for main_gml_id, group in bgt_roads_groups:\n",
    "    if main_gml_id in objects:\n",
    "        features = [f for i, f in group.iterrows()]\n",
    "        objects[main_gml_id]['geometry'].append(\n",
    "            create_geom_with_semantics(bgt_semantics_map,\n",
    "                                       features,\n",
    "                                       '2',\n",
    "                                       vertices)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's export everything as CityJSON:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import io\n",
    "\n",
    "output = {\n",
    "  \"type\": \"CityJSON\",\n",
    "  \"version\": \"1.0\",\n",
    "  \"CityObjects\": objects,\n",
    "  \"vertices\": vertices\n",
    "}\n",
    "\n",
    "with open('output/breda.json', 'w') as file:\n",
    "    json.dump(output, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix missing network and polygons\n",
    "We should create individual road objects for the polygons (and respective network segments) that do not have a `parent_gml_id`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate carriageways and lanes\n",
    "- Compute the carriageways only from OSM attributes.\n",
    "- Compute road width:\n",
    "     - We exclude intersections.\n",
    "- How we create the carriageways for twoway streets and more specifically for intersections.\n",
    "\n",
    "NOTE: Case of a two-way road where we figure out that the road width doesn't fit two lanes (special case were two ways share the same carriageway)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create perpendicular lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.ops import unary_union\n",
    "from shapely.geometry import Point, LineString\n",
    "\n",
    "offset = 100\n",
    "\n",
    "def get_vertex(line, first=True):\n",
    "    \"\"\"Returns the first or last vertex\"\"\"\n",
    "    if line.type == \"LineString\":\n",
    "        return line.boundary[0 if first else len(line.coords) - 1]\n",
    "    else:\n",
    "        return Point(0, 0)\n",
    "    \n",
    "\n",
    "def get_perpendicular_line(geom):\n",
    "    if geom.type == 'LineString':\n",
    "        left = geom.parallel_offset(offset, 'left')\n",
    "        right = geom.parallel_offset(offset, 'right')\n",
    "        a = get_vertex(left, False)\n",
    "        b = get_vertex(right, True)\n",
    "        return LineString([a, b])\n",
    "    else:\n",
    "        lines = []\n",
    "        for line in geom.geoms:\n",
    "            lines.append(get_perpendicular_line(line))\n",
    "        \n",
    "        return unary_union(lines)\n",
    "\n",
    "roads['perp_line'] = roads['geometry'].apply(get_perpendicular_line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate width\n",
    "Let's join the network lines with the polygons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common = roads.set_index('parent_gml_id').merge(bgt_all_roads.set_index('gml_id'), on='gml_id', suffixes=('', '_right'))\n",
    "\n",
    "common.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Old (and slow) way:\n",
    "We can compute the road width by computing perpendicular lines at one end of the network line and intersecting that with the polygon of the road. This is unreliable and slow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_width(polygon, line):\n",
    "    return polygon.intersection(line).length\n",
    "\n",
    "def compute_road_width(f):\n",
    "    return compute_width(f['geometry_right'], f['perp_line'])\n",
    "\n",
    "# common['road_width'] = common.apply(compute_road_width, axis=1)\n",
    "\n",
    "# common[['osmid', 'road_width', 'geometry']].to_file('output/road_widths.geojson', driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New (and fast) way:\n",
    "Why don't we just assume that the line equals with the length of the side of the road? Then, if we take the polygons perimeter, it's composed by twice the length of the road and twice the width. Easy, isn't it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_width_from_perimeter(f):\n",
    "    return f['geometry_right'].length / 2 - f['geometry'].length\n",
    "\n",
    "common_dissolved = common.dissolve(by='gml_id')\n",
    "\n",
    "common_dissolved['width'] = common_dissolved.apply(compute_width_from_perimeter, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_dissolved.reset_index()[['gml_id', 'width', 'geometry']].to_file('output/width_by_perimeter.geojson', driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduce flyovers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation and evaluation\n",
    "\n",
    "- Ensure completeless of network (run a simple routing problem)\n",
    "- Compute decorations like traffic lights\n",
    "- Potentionally compute more interesting algorithms, e.g. what the best route about de-icing given the width of street (exploiting the semantic surfaces here)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
